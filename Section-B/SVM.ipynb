{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have suppressed warnings that were flooding the output, making it harder for a better visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(action='ignore', category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.load(\"x.npy\")\n",
    "y_data = np.load(\"y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When splitting the dataset into train and test, it should be kept in mind that instance of every class must be present in both the sets atleast once. For the same, we have used StratifiedShuffleSplit to accomplish splitting the dataset into stratifically shuffled manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the test set size is taken as 20% as the whole dataset was of size 101, where there was animal \"frog\" twice and \"girl\" once, reducing the size to 99."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in sss.split(x_data, y_data):\n",
    "    x_train, x_test = x_data[train_index], x_data[test_index]\n",
    "    y_train, y_test = y_data[train_index], y_data[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 16), (21, 16))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2, 3, 4, 5, 6, 7]), array([33, 16,  4, 10,  3,  6,  8]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here classifiers is a list of Support Vector Classifiers with different kernels. The parameter \"probability=True\" is for calculating negative log loss of the model, i.e toggling predict_proba method. For kernel coefficient for 'rbf', 'poly' and 'sigmoid', gamma is set to 'auto' which uses 1 / n_features. (n_features = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [SVC(kernel=\"linear\", probability=True), SVC(kernel=\"rbf\", probability=True, gamma=\"auto\"), SVC(kernel=\"poly\", probability=True, gamma=\"auto\"), SVC(kernel=\"sigmoid\", probability=True, gamma=\"auto\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer(y, y_pred):\n",
    "    print(classification_report(y, y_pred))\n",
    "    return accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here for the k fold cross-validation we have used k=4 as the least popular class has total number of instances 4. So a cross validation of k = 5 is not possible. We have done k = 4, along with taking the entire dataset for the purpose such that k = 4 is atleast possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, x, y, cv=4):\n",
    "    print(\"K:\", cv)\n",
    "    print(\"Kernel:\", model.kernel.upper())\n",
    "    result = cross_validate(model, x, y, cv=cv, scoring=make_scorer(scorer), return_train_score=True)\n",
    "    print(\"Tests score:\", result[\"test_score\"])\n",
    "    print(\"Train score:\", result[\"train_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, We have echoed the full classification table where we can obtain the precision, recall and f1-score of every model trained during the cross-validation. First the testing report is printed for each model then the training report, at last for each kernel, an accuracy metric is also echoed for each of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 4\n",
      "Kernel: LINEAR\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        11\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       1.00      0.50      0.67         2\n",
      "           4       0.80      1.00      0.89         4\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       1.00      1.00      1.00         3\n",
      "\n",
      "   micro avg       0.96      0.96      0.96        28\n",
      "   macro avg       0.97      0.93      0.94        28\n",
      "weighted avg       0.97      0.96      0.96        28\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        30\n",
      "           2       1.00      1.00      1.00        15\n",
      "           3       1.00      1.00      1.00         3\n",
      "           4       1.00      1.00      1.00         9\n",
      "           5       1.00      1.00      1.00         3\n",
      "           6       1.00      1.00      1.00         6\n",
      "           7       1.00      1.00      1.00         7\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        73\n",
      "   macro avg       1.00      1.00      1.00        73\n",
      "weighted avg       1.00      1.00      1.00        73\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       1.00      1.00      1.00         1\n",
      "           4       1.00      1.00      1.00         3\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       0.67      1.00      0.80         2\n",
      "           7       1.00      0.67      0.80         3\n",
      "\n",
      "   micro avg       0.96      0.96      0.96        25\n",
      "   macro avg       0.95      0.95      0.94        25\n",
      "weighted avg       0.97      0.96      0.96        25\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        31\n",
      "           2       1.00      1.00      1.00        15\n",
      "           3       1.00      1.00      1.00         4\n",
      "           4       1.00      1.00      1.00        10\n",
      "           5       1.00      1.00      1.00         3\n",
      "           6       1.00      1.00      1.00         6\n",
      "           7       1.00      1.00      1.00         7\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        76\n",
      "   macro avg       1.00      1.00      1.00        76\n",
      "weighted avg       1.00      1.00      1.00        76\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       0.83      1.00      0.91         5\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       1.00      1.00      1.00         3\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       1.00      1.00      1.00         2\n",
      "\n",
      "   micro avg       0.92      0.92      0.92        24\n",
      "   macro avg       0.69      0.71      0.70        24\n",
      "weighted avg       0.88      0.92      0.90        24\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        31\n",
      "           2       1.00      1.00      1.00        15\n",
      "           3       1.00      1.00      1.00         4\n",
      "           4       1.00      1.00      1.00        10\n",
      "           5       1.00      1.00      1.00         3\n",
      "           6       1.00      1.00      1.00         6\n",
      "           7       1.00      1.00      1.00         8\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        77\n",
      "   macro avg       1.00      1.00      1.00        77\n",
      "weighted avg       1.00      1.00      1.00        77\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       1.00      1.00      1.00         3\n",
      "           5       0.50      1.00      0.67         1\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       1.00      1.00      1.00         2\n",
      "\n",
      "   micro avg       0.96      0.96      0.96        24\n",
      "   macro avg       0.79      0.86      0.81        24\n",
      "weighted avg       0.94      0.96      0.94        24\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        31\n",
      "           2       1.00      1.00      1.00        15\n",
      "           3       1.00      1.00      1.00         4\n",
      "           4       1.00      1.00      1.00        10\n",
      "           5       1.00      1.00      1.00         3\n",
      "           6       1.00      1.00      1.00         6\n",
      "           7       1.00      1.00      1.00         8\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        77\n",
      "   macro avg       1.00      1.00      1.00        77\n",
      "weighted avg       1.00      1.00      1.00        77\n",
      "\n",
      "Tests score: [ 0.96428571  0.96        0.91666667  0.95833333]\n",
      "Train score: [ 1.  1.  1.  1.]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "K: 4\n",
      "Kernel: RBF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        11\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.67      1.00      0.80         4\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       1.00      1.00      1.00         3\n",
      "\n",
      "   micro avg       0.93      0.93      0.93        28\n",
      "   macro avg       0.81      0.86      0.83        28\n",
      "weighted avg       0.88      0.93      0.90        28\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      1.00      0.95        30\n",
      "           2       1.00      1.00      1.00        15\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.90      1.00      0.95         9\n",
      "           5       1.00      0.67      0.80         3\n",
      "           6       1.00      1.00      1.00         6\n",
      "           7       1.00      1.00      1.00         7\n",
      "\n",
      "   micro avg       0.95      0.95      0.95        73\n",
      "   macro avg       0.83      0.81      0.81        73\n",
      "weighted avg       0.91      0.95      0.92        73\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.75      1.00      0.86         3\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       0.50      1.00      0.67         2\n",
      "           7       1.00      0.33      0.50         3\n",
      "\n",
      "   micro avg       0.88      0.88      0.88        25\n",
      "   macro avg       0.75      0.76      0.72        25\n",
      "weighted avg       0.89      0.88      0.86        25\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      1.00      0.95        31\n",
      "           2       1.00      1.00      1.00        15\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.83      1.00      0.91        10\n",
      "           5       1.00      0.67      0.80         3\n",
      "           6       1.00      1.00      1.00         6\n",
      "           7       1.00      1.00      1.00         7\n",
      "\n",
      "   micro avg       0.93      0.93      0.93        76\n",
      "   macro avg       0.82      0.81      0.81        76\n",
      "weighted avg       0.89      0.93      0.91        76\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      1.00      0.95        10\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       1.00      1.00      1.00         3\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       1.00      0.50      0.67         2\n",
      "\n",
      "   micro avg       0.92      0.92      0.92        24\n",
      "   macro avg       0.84      0.79      0.80        24\n",
      "weighted avg       0.92      0.92      0.91        24\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      1.00      0.98        31\n",
      "           2       1.00      1.00      1.00        15\n",
      "           3       1.00      0.25      0.40         4\n",
      "           4       0.83      1.00      0.91        10\n",
      "           5       1.00      1.00      1.00         3\n",
      "           6       1.00      1.00      1.00         6\n",
      "           7       1.00      1.00      1.00         8\n",
      "\n",
      "   micro avg       0.96      0.96      0.96        77\n",
      "   macro avg       0.97      0.89      0.90        77\n",
      "weighted avg       0.97      0.96      0.95        77\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      1.00      0.91        10\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       1.00      1.00      1.00         3\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       1.00      1.00      1.00         2\n",
      "\n",
      "   micro avg       0.92      0.92      0.92        24\n",
      "   macro avg       0.69      0.71      0.70        24\n",
      "weighted avg       0.85      0.92      0.88        24\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      1.00      0.97        31\n",
      "           2       1.00      1.00      1.00        15\n",
      "           3       1.00      0.25      0.40         4\n",
      "           4       0.83      1.00      0.91        10\n",
      "           5       1.00      0.67      0.80         3\n",
      "           6       1.00      1.00      1.00         6\n",
      "           7       1.00      1.00      1.00         8\n",
      "\n",
      "   micro avg       0.95      0.95      0.95        77\n",
      "   macro avg       0.97      0.85      0.87        77\n",
      "weighted avg       0.95      0.95      0.94        77\n",
      "\n",
      "Tests score: [ 0.92857143  0.88        0.91666667  0.91666667]\n",
      "Train score: [ 0.94520548  0.93421053  0.96103896  0.94805195]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "K: 4\n",
      "Kernel: POLY\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.91      0.95        11\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.50      1.00      0.67         4\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       1.00      0.67      0.80         3\n",
      "\n",
      "   micro avg       0.86      0.86      0.86        28\n",
      "   macro avg       0.79      0.80      0.77        28\n",
      "weighted avg       0.86      0.86      0.84        28\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.93      0.97        30\n",
      "           2       1.00      1.00      1.00        15\n",
      "           3       1.00      0.67      0.80         3\n",
      "           4       0.60      1.00      0.75         9\n",
      "           5       1.00      1.00      1.00         3\n",
      "           6       1.00      1.00      1.00         6\n",
      "           7       1.00      0.57      0.73         7\n",
      "\n",
      "   micro avg       0.92      0.92      0.92        73\n",
      "   macro avg       0.94      0.88      0.89        73\n",
      "weighted avg       0.95      0.92      0.92        73\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.75      1.00      0.86         3\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       0.50      1.00      0.67         2\n",
      "           7       1.00      0.33      0.50         3\n",
      "\n",
      "   micro avg       0.88      0.88      0.88        25\n",
      "   macro avg       0.75      0.76      0.72        25\n",
      "weighted avg       0.89      0.88      0.86        25\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.90      0.95        31\n",
      "           2       1.00      1.00      1.00        15\n",
      "           3       1.00      0.50      0.67         4\n",
      "           4       0.53      1.00      0.69        10\n",
      "           5       1.00      1.00      1.00         3\n",
      "           6       1.00      1.00      1.00         6\n",
      "           7       1.00      0.43      0.60         7\n",
      "\n",
      "   micro avg       0.88      0.88      0.88        76\n",
      "   macro avg       0.93      0.83      0.84        76\n",
      "weighted avg       0.94      0.88      0.88        76\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.50      1.00      0.67         3\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.83      0.83      0.83        24\n",
      "   macro avg       0.63      0.70      0.65        24\n",
      "weighted avg       0.77      0.83      0.79        24\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.94      0.97        31\n",
      "           2       1.00      1.00      1.00        15\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.59      1.00      0.74        10\n",
      "           5       0.75      1.00      0.86         3\n",
      "           6       1.00      1.00      1.00         6\n",
      "           7       1.00      0.75      0.86         8\n",
      "\n",
      "   micro avg       0.90      0.90      0.90        77\n",
      "   macro avg       0.76      0.81      0.77        77\n",
      "weighted avg       0.88      0.90      0.88        77\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.80      0.89        10\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.50      1.00      0.67         3\n",
      "           5       0.50      1.00      0.67         1\n",
      "           6       1.00      1.00      1.00         2\n",
      "           7       1.00      0.50      0.67         2\n",
      "\n",
      "   micro avg       0.83      0.83      0.83        24\n",
      "   macro avg       0.71      0.76      0.70        24\n",
      "weighted avg       0.88      0.83      0.83        24\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.90      0.95        31\n",
      "           2       0.94      1.00      0.97        15\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.53      1.00      0.69        10\n",
      "           5       1.00      1.00      1.00         3\n",
      "           6       1.00      1.00      1.00         6\n",
      "           7       1.00      0.62      0.77         8\n",
      "\n",
      "   micro avg       0.87      0.87      0.87        77\n",
      "   macro avg       0.78      0.79      0.77        77\n",
      "weighted avg       0.87      0.87      0.86        77\n",
      "\n",
      "Tests score: [ 0.85714286  0.88        0.83333333  0.83333333]\n",
      "Train score: [ 0.91780822  0.88157895  0.8961039   0.87012987]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "K: 4\n",
      "Kernel: SIGMOID\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.91      0.80        11\n",
      "           2       0.71      1.00      0.83         5\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.57      1.00      0.73         4\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.68      0.68      0.68        28\n",
      "   macro avg       0.29      0.42      0.34        28\n",
      "weighted avg       0.49      0.68      0.57        28\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.97      0.87        30\n",
      "           2       0.62      1.00      0.77        15\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.75      1.00      0.86         9\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         6\n",
      "           7       0.00      0.00      0.00         7\n",
      "\n",
      "   micro avg       0.73      0.73      0.73        73\n",
      "   macro avg       0.31      0.42      0.36        73\n",
      "weighted avg       0.54      0.73      0.62        73\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      1.00      0.95        10\n",
      "           2       0.50      1.00      0.67         5\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.75      1.00      0.86         3\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.72      0.72      0.72        25\n",
      "   macro avg       0.31      0.43      0.35        25\n",
      "weighted avg       0.55      0.72      0.62        25\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.81      0.94      0.87        31\n",
      "           2       0.68      1.00      0.81        15\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.71      1.00      0.83        10\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         6\n",
      "           7       1.00      0.57      0.73         7\n",
      "\n",
      "   micro avg       0.76      0.76      0.76        76\n",
      "   macro avg       0.46      0.50      0.46        76\n",
      "weighted avg       0.65      0.76      0.69        76\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.90      0.86        10\n",
      "           2       0.62      1.00      0.77         5\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.60      1.00      0.75         3\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.71      0.71      0.71        24\n",
      "   macro avg       0.29      0.41      0.34        24\n",
      "weighted avg       0.55      0.71      0.61        24\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.97      0.86        31\n",
      "           2       0.68      1.00      0.81        15\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.67      1.00      0.80        10\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         6\n",
      "           7       1.00      0.12      0.22         8\n",
      "\n",
      "   micro avg       0.73      0.73      0.73        77\n",
      "   macro avg       0.45      0.44      0.38        77\n",
      "weighted avg       0.63      0.73      0.63        77\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      1.00      0.87        10\n",
      "           2       0.62      1.00      0.77         5\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       1.00      1.00      1.00         3\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.75      0.75      0.75        24\n",
      "   macro avg       0.34      0.43      0.38        24\n",
      "weighted avg       0.58      0.75      0.65        24\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.94      0.91        31\n",
      "           2       0.54      1.00      0.70        15\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.67      1.00      0.80        10\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         6\n",
      "           7       1.00      0.12      0.22         8\n",
      "\n",
      "   micro avg       0.71      0.71      0.71        77\n",
      "   macro avg       0.44      0.44      0.38        77\n",
      "weighted avg       0.65      0.71      0.63        77\n",
      "\n",
      "Tests score: [ 0.67857143  0.72        0.70833333  0.75      ]\n",
      "Train score: [ 0.7260274   0.76315789  0.72727273  0.71428571]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    evaluate(classifier, x_data, y_data)\n",
    "    print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking into the cross-validation classification report of these SVCs we can deduce that, **Linear** kernels are the best performing at default settings followed by **RBF** then **POLYNOMIAL** and **SIGMOID** kernels in that order."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
